{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from retinaface.pre_trained_models import get_model\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "retina_face_model = get_model(\"resnet50_2020-07-20\", max_size=2048)\n",
    "retina_face_model.eval() \n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet_model = torch.load('resnet_model.pt')\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def get_embedding(face_pixels):\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    resized1 = torch.from_numpy(face_pixels)\n",
    "    resized1= resized1.permute(2,0,1)\n",
    "    img_cropped = torch.unsqueeze(resized1, dim=0)\n",
    "    img_embedding  = resnet_model(img_cropped)\n",
    "    return img_embedding.detach().numpy()\n",
    "\n",
    "def calculate_sim_score(image_embed1,image_embed2) -> float:\n",
    "    \"\"\"Calclulate Similarity Scores from Image embedding \n",
    "    bytes datatype to ndarray format.\n",
    "    Args:\n",
    "        image_embed1 (tensor(1,512)): image embedding for image 1\n",
    "        image_embed2 (tensor(1,512)): image embedding for image 2\n",
    "    Returns:\n",
    "        sim_score  (float): Similarity Socre\n",
    "    \"\"\"\n",
    "    sim_scores = F.cosine_similarity(image_embed1,image_embed2).detach().numpy()\n",
    "    sim_score = np.clip(sim_scores,a_min=0.0,a_max=1.0)[0]\n",
    "    return sim_score\n",
    "\n",
    "def fn_return_sim_score(img_embedding):\n",
    "    write_flag = False\n",
    "    ecu_dists = np.array([])\n",
    "    sim_scores = np.array([])\n",
    "    id = None\n",
    "    sim_score = 0\n",
    "    ecu_dist = 0\n",
    "    for file in os.listdir(r'anchor_embedding'):\n",
    "        # embedding1.npy\n",
    "        embedding1 = np.load('anchor_embedding/'+file)\n",
    "        img_embedding = img_embedding.reshape(-1)\n",
    "        embedding1 = embedding1.reshape(-1)\n",
    "        # print(img_embedding.shape,embedding1.shape)\n",
    "        cosine_sim = np.dot(img_embedding,embedding1)/(norm(img_embedding)*norm(embedding1))\n",
    "        dist = np.linalg.norm(img_embedding-embedding1)        \n",
    "        # img_embedding1 = np.load(r'anchor_embedding/'+file)\n",
    "        # img_embedding1 = torch.from_numpy(img_embedding1)\n",
    "        # sim_score = calculate_sim_score(img_embedding1,img_embedding)\n",
    "        # sim_score = sim_score * 100\n",
    "        sim_scores = np.append(sim_scores,cosine_sim)\n",
    "        ecu_dists = np.append(ecu_dists,dist)\n",
    "        # print(cosine_sim,dist)\n",
    "    if len(ecu_dists) != 0:\n",
    "        id = np.argmin(ecu_dists) \n",
    "        ecu_dist = ecu_dists[id] \n",
    "    if len(sim_scores) != 0:\n",
    "        id = np.argmax(sim_scores) \n",
    "        sim_score = sim_scores[id] * 100 \n",
    "        id = id + 1       \n",
    "    if sim_score < 60:\n",
    "        write_flag = True\n",
    "    print(id,ecu_dist,sim_score)\n",
    "    return ecu_dist,write_flag,id,sim_score\n",
    "\n",
    "def getFrame(sec,vidcap,detection_model,out,count):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,frame = vidcap.read()\n",
    "    resized = None\n",
    "    break_flag = None\n",
    "    cropped_image = None\n",
    "    sim_score = 0\n",
    "    ecu_dist = 0\n",
    "    if hasFrames:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        annotations = retina_face_model.predict_jsons(image)\n",
    "        color = (255, 0, 0)\n",
    "        for annotation in annotations:\n",
    "            prob  = annotation['score'] * 100\n",
    "            margin = 5\n",
    "            if annotation[\"score\"] != -1:\n",
    "                x_min, y_min, x_max, y_max = annotation[\"bbox\"]\n",
    "                box_area = (int(x_max) - int(x_min)) * (int(y_max) - int(y_min))                    \n",
    "                if box_area > 5000:                  \n",
    "                    x_min = np.clip(x_min, 0, x_max - 1)\n",
    "                    y_min = np.clip(y_min, 0, y_max - 1)\n",
    "                    box_area = (int(x_max) - int(x_min)) * (int(y_max) - int(y_min))\n",
    "                    bb = np.array([int(x_min) ,int(y_min),int(x_max),int(y_max)], dtype=np.int32)           \n",
    "                    cropped = image[bb[1]:bb[3], bb[0]:bb[2], :].copy()\n",
    "                    frame = cv2.rectangle(frame,(int(x_min),int(y_min)),(int(x_max),int(y_max)),(255, 0, 0) ,4)\n",
    "                    landmarks_cropped = np.array(annotation['landmarks'])\n",
    "                    leftEyeCenter = np.array(landmarks_cropped[0])\n",
    "                    rightEyeCenter = np.array(landmarks_cropped[1])\n",
    "                    dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "                    dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "                    angle = np.degrees(np.arctan2(dY, dX)) \n",
    "                    # print(angle)\n",
    "                    dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "                    # desiredDist = 0.4\n",
    "                    # desiredDist *= desiredFaceWidth\n",
    "                    scale = 1\n",
    "                    height, width = cropped.shape[:2]\n",
    "# get the center coordinates of the \n",
    "# image to create the 2D rotation matrix\n",
    "                    center = (width/2, height/2)\n",
    "                    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "                    x1,y1 = np.dot(M,np.array([bb[0],bb[1],1]).T)\n",
    "                    x2,y2 = np.dot(M,np.array([bb[2],bb[3],1]).T)\n",
    "                    # print((x_max - x_min))\n",
    "                    aspect_ratio = (y2 - y1)/(x2 - x1)\n",
    "                    margin = 35\n",
    "                    print(aspect_ratio)\n",
    "                    if aspect_ratio > 1.5:\n",
    "                        x1 = int(max(0,x1-(margin * aspect_ratio )))\n",
    "                        x2 = int(x2+(margin *aspect_ratio ))\n",
    "\n",
    "                    # M[1, 2] += (tY - eyesCenter[1]) \n",
    "                    h,w = image.shape[:2]\n",
    "\n",
    "                    output = cv2.warpAffine(image, M, (w, w),\n",
    "                        flags=cv2.INTER_CUBIC)  \n",
    "                    cropped = output.copy()\n",
    "                    cropped = cropped[int(y1):int(y2),int(x1):int(x2),:]\n",
    "                    output = cv2.rectangle(output,(int(x1),int(y1)),(int(x2),int(y2)),(255, 0, 0) ,4)\n",
    "                    cv2.imwrite(\"aligned_face_img\"+str(count)+\".jpg\", output) \n",
    "                    count = count + 1                           \n",
    "                    if not os.path.exists('anchor_embedding'):\n",
    "                        os.makedirs('anchor_embedding')     \n",
    "                    if not os.path.exists('anchor_images'):\n",
    "                        os.makedirs('anchor_images')                                                                       \n",
    "                    resized = cv2.resize(cropped, (160,160), interpolation = cv2.INTER_AREA)\n",
    "                    embeddings_list = os.listdir(r'anchor_embedding') \n",
    "                    img_embedding = get_embedding(resized)\n",
    "                    if len(embeddings_list) != 0:                    \n",
    "                        ecu_dist,write_flag,id,sim_score = fn_return_sim_score(img_embedding)\n",
    "                    else:\n",
    "                        write_flag = True  \n",
    "                    if write_flag == True:\n",
    "                        id = len(embeddings_list) + 1\n",
    "                        np.save(r\"anchor_embedding/\"+'embedding'+str(id),img_embedding)                    \n",
    "                        cropped = cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR)\n",
    "                        cv2.imwrite(r\"anchor_images/\"+\"image\"+str(id)+\".jpg\", cropped)  \n",
    "                        # print(annotation[\"bbox\"],annotation[\"score\"],ecu_dist,sim_score)                     \n",
    "                    if write_flag == False:\n",
    "                        frame = cv2.putText(frame, 'Similarity score ' + str(int(sim_score)) + '  Id ' + str(id) , (int(x_min),int(y_min)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)                        \n",
    "                        # print(annotation[\"bbox\"],annotation[\"score\"],ecu_dist,sim_score,str(id))\n",
    "                    out.write(frame)\n",
    "    return hasFrames,break_flag,count\n",
    "\n",
    "                \n",
    "\n",
    "vidcap = cv2.VideoCapture('Webcam_test.mov')\n",
    "sec = 0\n",
    "frameRate = 0.5 #//it will capture image in each 0.5 second\n",
    "count=1\n",
    "frame_width = int(vidcap.get(3))\n",
    "frame_height = int(vidcap.get(4))\n",
    "\n",
    "detection_model = 'retinaface'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('webcam_test_op.mp4', fourcc, 20.0, (frame_width,frame_height))\n",
    "count = 0\n",
    "hasFrames,break_flag,count = getFrame(sec,vidcap,detection_model,out,count)\n",
    "\n",
    "while hasFrames:\n",
    "    # count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    hasFrames,break_flag,count = getFrame(sec,vidcap,detection_model,out,count)\n",
    "    if break_flag == True:\n",
    "        break\n",
    "\n",
    "vidcap.release()\n",
    "out.release()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
