{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitgupta/Documents/Face-Track-Detect-Extract/env/lib/python3.9/site-packages/torch/hub.py:480: UserWarning: Falling back to the old format < 1.6. This support will be deprecated in favor of default zipfile format introduced in 1.6. Please redo torch.save() to save it in the new zipfile format.\n",
      "  warnings.warn('Falling back to the old format < 1.6. This support will be '\n",
      "OpenCV: AVFoundation didn't find any attached Video Input Devices!\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot open webcam",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m# frame_width = int(cap.get(3))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# frame_height = int(cap.get(4))\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot open webcam\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot open webcam"
     ]
    }
   ],
   "source": [
    "\n",
    "from retinaface.pre_trained_models import get_model\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "retina_face_model = get_model(\"resnet50_2020-07-20\", max_size=2048)\n",
    "retina_face_model.eval() \n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet_model = torch.load('resnet_model.pt')\n",
    "import os\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def get_embedding(face_pixels):\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    resized1 = torch.from_numpy(face_pixels)\n",
    "    resized1= resized1.permute(2,1,0)\n",
    "    img_cropped = torch.unsqueeze(resized1, dim=0)\n",
    "    img_embedding  = resnet_model(img_cropped)\n",
    "    return img_embedding\n",
    "\n",
    "def calculate_sim_score(image_embed1,image_embed2) -> float:\n",
    "    \"\"\"Calclulate Similarity Scores from Image embedding \n",
    "    bytes datatype to ndarray format.\n",
    "    Args:\n",
    "        image_embed1 (tensor(1,512)): image embedding for image 1\n",
    "        image_embed2 (tensor(1,512)): image embedding for image 2\n",
    "    Returns:\n",
    "        sim_score  (float): Similarity Socre\n",
    "    \"\"\"\n",
    "    sim_scores = F.cosine_similarity(image_embed1,image_embed2).detach().numpy()\n",
    "    sim_score = np.clip(sim_scores,a_min=0.0,a_max=1.0)[0]\n",
    "    return sim_score\n",
    "\n",
    "def fn_return_sim_score(img_embedding):\n",
    "    write_flag = False\n",
    "    sim_scores = np.array([])\n",
    "    id = None\n",
    "    for file in os.listdir(r'anchor_embedding'):\n",
    "        img_embedding1 = np.load(r'anchor_embedding/'+file)\n",
    "        img_embedding1 = torch.from_numpy(img_embedding1)\n",
    "        sim_score = calculate_sim_score(img_embedding1,img_embedding)\n",
    "        sim_score = sim_score * 100\n",
    "        sim_scores = np.append(sim_scores,sim_score)\n",
    "    if len(sim_scores) != 0:\n",
    "        id = np.argmax(sim_scores) \n",
    "        sim_score = sim_scores[id] \n",
    "        id = id + 1       \n",
    "    if sim_score < 45:\n",
    "        write_flag = True\n",
    "    return sim_score,write_flag,id\n",
    "### video inference and wirte frames on list\n",
    "import numpy as np\n",
    "\n",
    "### reading every 10th Frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# frame_width = int(cap.get(3))\n",
    "# frame_height = int(cap.get(4))\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        annotations = retina_face_model.predict_jsons(image)\n",
    "        color = (255, 0, 0)\n",
    "        for annotation in annotations:\n",
    "            prob  = annotation['score'] * 100\n",
    "            # box_area = (int(x_max) - int(x_min)) * (int(y_max) - int(y_min))\n",
    "            print(annotation[\"bbox\"],annotation[\"score\"])\n",
    "            if annotation[\"score\"] != -1:\n",
    "                x_min, y_min, x_max, y_max = annotation[\"bbox\"]                      \n",
    "                x_min = np.clip(x_min, 0, x_max - 1)\n",
    "                y_min = np.clip(y_min, 0, y_max - 1)\n",
    "                box_area = (int(x_max) - int(x_min)) * (int(y_max) - int(y_min))\n",
    "                bb = np.array([int(x_min),int(y_min),int(x_max),int(y_max)], dtype=np.int32)\n",
    "                cropped = frame[bb[1]:bb[3], bb[0]:bb[2], :].copy()\n",
    "                \n",
    "                if not os.path.exists('anchor_embedding'):\n",
    "                    os.makedirs('anchor_embedding')     \n",
    "                if not os.path.exists('anchor_images'):\n",
    "                    os.makedirs('anchor_images')                                                                       \n",
    "                resized = cv2.resize(cropped, (160,160), interpolation = cv2.INTER_AREA)\n",
    "                embeddings_list = os.listdir(r'anchor_embedding') \n",
    "                img_embedding = get_embedding(resized)\n",
    "                if len(embeddings_list) != 0:                    \n",
    "                    sim_score,write_flag,id = fn_return_sim_score(img_embedding)\n",
    "                else:\n",
    "                    write_flag = True  \n",
    "                if write_flag == True:\n",
    "                    id = len(embeddings_list) + 1\n",
    "                    np.save(r\"anchor_embedding/\"+'embedding'+str(id),img_embedding.deqtach().numpy())\n",
    "                    cropped = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(r\"anchor_images/\"+\"image\"+str(id)+\".jpg\", cropped)         \n",
    "                image = cv2.rectangle(image,(int(x_min),int(y_min)),(int(x_max),int(y_max)),(255, 0, 0) ,4)\n",
    "                if write_flag == False:\n",
    "                    image = cv2.putText(image, 'Similarity score ' + str(int(sim_score)) + '  Id ' + str(id) , (int(x_min),int(y_min)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)                        \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(r\"image\"+str(id)+\".jpg\", image)\n",
    "        window_name = 'image'\n",
    "        cv2.imshow(window_name,image)\n",
    "\n",
    "    keys = cv2.waitKey(1) & 0xFF\n",
    "    print(keys)\n",
    "    if keys == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
